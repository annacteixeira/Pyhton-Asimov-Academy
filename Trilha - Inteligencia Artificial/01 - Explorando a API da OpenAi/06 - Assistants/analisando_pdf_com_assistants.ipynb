{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "client = openai.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = client.beta.vector_stores.create(name = 'Apostilas Asimov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    'arquivos/Explorando a API da OpenAI.pdf',\n",
    "    'arquivos/Explorando o Universo das IAs com Hugging Face.pdf'\n",
    "]\n",
    "\n",
    "file_stream = [open(f, 'rb') for f in files]\n",
    "\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "    vector_store_id=vector_store.id,\n",
    "    files=file_stream\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "FileCounts(cancelled=0, completed=2, failed=0, in_progress=0, total=2)\n"
     ]
    }
   ],
   "source": [
    "print(file_batch.status)\n",
    "print(file_batch.file_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name='Tutor',\n",
    "    instructions='''\n",
    "        Você é um tutor de uma escola de programação.\n",
    "        Você é ótimo para responder perguntas teóricas sobre a api da OpenAI e sobre a utilização\n",
    "        da biblioteca Hugging Face com Python. Você utiliza as apostilas dos cursos para basear suas respostas.\n",
    "        Caso você não encontre as respostas nas apostilas informadas, você fala que não sabe a resposta. \n",
    "    ''',\n",
    "    tools=[{'type':'file_search'}],\n",
    "    tool_resources={'file_search':{'vector_store_ids':[vector_store.id]}},\n",
    "    model='gpt-3.5-turbo-0125'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mensagem_texto = 'Segundo o documento fornecido, o que é o Hugging Face?'\n",
    "mensagem_texto = 'Segundo o documento fornecido, como utilizar assistants com Python?'\n",
    "\n",
    "messages = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role='user',\n",
    "    content=mensagem_texto\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    instructions='O nome do usuário é Anna e ela é um usuário Premium'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "while run.status in ['queued', 'in_progress', 'cancelling']:\n",
    "    time.sleep(1)\n",
    "    run = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id\n",
    "    )\n",
    "print(run.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[Message](data=[Message(id='msg_c8LznfC7dfx4MQsVdubGN2rD', assistant_id='asst_NaQOlPDwR6WIWfniFhtXDODg', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[FileCitationAnnotation(end_index=864, file_citation=FileCitation(file_id='file-PovZdD8NM7TgpkKNvVe7sr'), start_index=852, text='【8:0†source】', type='file_citation'), FileCitationAnnotation(end_index=876, file_citation=FileCitation(file_id='file-PovZdD8NM7TgpkKNvVe7sr'), start_index=864, text='【8:1†source】', type='file_citation'), FileCitationAnnotation(end_index=888, file_citation=FileCitation(file_id='file-PovZdD8NM7TgpkKNvVe7sr'), start_index=876, text='【8:3†source】', type='file_citation')], value='Para utilizar assistentes com Python, é possível seguir os seguintes passos conforme o documento \"Explorando a API da OpenAI.pdf\":\\n\\n1. Inicialize o cliente da OpenAI utilizando o código fornecido no documento.\\n2. Crie um assistente com uma instrução específica, como por exemplo, um assistente que responda perguntas de matemática e tenha acesso à ferramenta de interpretação de código.\\n3. Crie uma thread de comunicação com o assistente, adicionando mensagens a ela.\\n4. Solicite ao assistente para rodar a thread e aguarde a finalização do processo.\\n5. Verifique a resposta gerada pelo assistente, solicitando a lista de mensagens da thread e extraindo a mensagem final em formato de texto.\\n\\nEsses passos envolvem a criação do assistente, a interação por meio de threads e a obtenção das respostas geradas pelo modelo de assistente da OpenAI em Python【8:0†source】【8:1†source】【8:3†source】.'), type='text')], created_at=1734703464, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_87FS8DowACgwZ9FB4KdhcRA5', status=None, thread_id='thread_W13L2M3tnb9MJDqzIZ2bRRCZ'), Message(id='msg_9h0FZLfmWyZPBDCepbCSxDi4', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Segundo o documento fornecido, como utilizar assistants com Python?'), type='text')], created_at=1734703458, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_W13L2M3tnb9MJDqzIZ2bRRCZ'), Message(id='msg_7C2zK5CrtfqlOhv3JPAZY0DN', assistant_id='asst_NaQOlPDwR6WIWfniFhtXDODg', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[FileCitationAnnotation(end_index=297, file_citation=FileCitation(file_id='file-Gk7Tw2G5VTNsRNwqndUVMK'), start_index=285, text='【4:0†source】', type='file_citation'), FileCitationAnnotation(end_index=711, file_citation=FileCitation(file_id='file-Gk7Tw2G5VTNsRNwqndUVMK'), start_index=699, text='【4:0†source】', type='file_citation')], value='O Hugging Face é uma empresa que começou em 2017 na França, inicialmente focada no desenvolvimento de Chatbots. Com o tempo, a empresa evoluiu para desenvolver uma infraestrutura própria e bibliotecas de Python que facilitam o uso de modelos de Processamento de Linguagem Natural (NLP)【4:0†source】. A empresa se tornou conhecida por desenvolver uma plataforma colaborativa para a comunidade de Inteligência Artificial, onde pesquisadores, empresas e entusiastas podem compartilhar modelos de IA e conjuntos de dados para diversas tarefas. Em 2023, a empresa atingiu um valor de mercado de 4.5 bilhões de dólares, recebendo investimentos de empresas como Google, Meta, Microsoft, Nvidia, entre outras【4:0†source】.'), type='text')], created_at=1734702034, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_CcGXpzUdIoZnmVfvHoc6MOAZ', status=None, thread_id='thread_W13L2M3tnb9MJDqzIZ2bRRCZ'), Message(id='msg_j6wy6bcaBsyM55WUc4oKr3hc', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Segundo o documento fornecido, o que é o Hugging Face?'), type='text')], created_at=1734702028, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_W13L2M3tnb9MJDqzIZ2bRRCZ')], object='list', first_id='msg_c8LznfC7dfx4MQsVdubGN2rD', last_id='msg_j6wy6bcaBsyM55WUc4oKr3hc', has_more=False)\n"
     ]
    }
   ],
   "source": [
    "if run.status == 'completed':\n",
    "    mensagens = client.beta.threads.messages.list(\n",
    "        thread_id=thread.id\n",
    "    )\n",
    "    print(mensagens)\n",
    "else:\n",
    "    print('Erro', run.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para utilizar assistentes com Python, é possível seguir os seguintes passos conforme o documento \"Explorando a API da OpenAI.pdf\":\n",
      "\n",
      "1. Inicialize o cliente da OpenAI utilizando o código fornecido no documento.\n",
      "2. Crie um assistente com uma instrução específica, como por exemplo, um assistente que responda perguntas de matemática e tenha acesso à ferramenta de interpretação de código.\n",
      "3. Crie uma thread de comunicação com o assistente, adicionando mensagens a ela.\n",
      "4. Solicite ao assistente para rodar a thread e aguarde a finalização do processo.\n",
      "5. Verifique a resposta gerada pelo assistente, solicitando a lista de mensagens da thread e extraindo a mensagem final em formato de texto.\n",
      "\n",
      "Esses passos envolvem a criação do assistente, a interação por meio de threads e a obtenção das respostas geradas pelo modelo de assistente da OpenAI em Python【8:0†source】【8:1†source】【8:3†source】.\n"
     ]
    }
   ],
   "source": [
    "print(mensagens.data[0].content[0].text.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_steps = client.beta.threads.runs.steps.list(\n",
    "    thread_id=thread.id,\n",
    "    run_id=run.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step: message_creation\n",
      "Para utilizar assistentes com Python, é possível seguir os seguintes passos conforme o documento \"Explorando a API da OpenAI.pdf\":\n",
      "\n",
      "1. Inicialize o cliente da OpenAI utilizando o código fornecido no documento.\n",
      "2. Crie um assistente com uma instrução específica, como por exemplo, um assistente que responda perguntas de matemática e tenha acesso à ferramenta de interpretação de código.\n",
      "3. Crie uma thread de comunicação com o assistente, adicionando mensagens a ela.\n",
      "4. Solicite ao assistente para rodar a thread e aguarde a finalização do processo.\n",
      "5. Verifique a resposta gerada pelo assistente, solicitando a lista de mensagens da thread e extraindo a mensagem final em formato de texto.\n",
      "\n",
      "Esses passos envolvem a criação do assistente, a interação por meio de threads e a obtenção das respostas geradas pelo modelo de assistente da OpenAI em Python【8:0†source】【8:1†source】【8:3†source】.\n",
      "=== Step: tool_calls\n",
      "FileSearchToolCall(id='call_6SaYS9lgly13J1tIdxryYPxw', file_search=FileSearch(ranking_options=FileSearchRankingOptions(ranker='default_2024_08_21', score_threshold=0.0), results=[FileSearchResult(file_id='file-PovZdD8NM7TgpkKNvVe7sr', file_name='Explorando a API da OpenAI.pdf', score=0.901235705881537, content=None), FileSearchResult(file_id='file-PovZdD8NM7TgpkKNvVe7sr', file_name='Explorando a API da OpenAI.pdf', score=0.8909109316026959, content=None), FileSearchResult(file_id='file-PovZdD8NM7TgpkKNvVe7sr', file_name='Explorando a API da OpenAI.pdf', score=0.822490716842986, content=None), FileSearchResult(file_id='file-PovZdD8NM7TgpkKNvVe7sr', file_name='Explorando a API da OpenAI.pdf', score=0.7566137784892653, content=None), FileSearchResult(file_id='file-PovZdD8NM7TgpkKNvVe7sr', file_name='Explorando a API da OpenAI.pdf', score=0.7457137189839447, content=None)]), type='file_search')\n"
     ]
    }
   ],
   "source": [
    "for step in run_steps.data:\n",
    "    print('=== Step:', step.step_details.type)\n",
    "    if step.step_details.type == 'tool_calls':\n",
    "        for tool_call in step.step_details.tool_calls:\n",
    "            if tool_call.type == 'file_search':\n",
    "                print(tool_call)\n",
    "            else:\n",
    "                print('----------')\n",
    "                print(tool_call.code_interpreter.input)\n",
    "                print('----------')\n",
    "                print('Result')\n",
    "                print(tool_call.code_interpreter.outputs[0].logs)\n",
    "    if step.step_details.type == 'message_creation':\n",
    "        message = client.beta.threads.messages.retrieve(\n",
    "            thread_id=thread.id,\n",
    "            message_id=step.step_details.message_creation.message_id\n",
    "        )\n",
    "        print(message.content[0].text.value)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text(annotations=[FileCitationAnnotation(end_index=864, file_citation=FileCitation(file_id='file-PovZdD8NM7TgpkKNvVe7sr'), start_index=852, text='【8:0†source】', type='file_citation'), FileCitationAnnotation(end_index=876, file_citation=FileCitation(file_id='file-PovZdD8NM7TgpkKNvVe7sr'), start_index=864, text='【8:1†source】', type='file_citation'), FileCitationAnnotation(end_index=888, file_citation=FileCitation(file_id='file-PovZdD8NM7TgpkKNvVe7sr'), start_index=876, text='【8:3†source】', type='file_citation')], value='Para utilizar assistentes com Python, é possível seguir os seguintes passos conforme o documento \"Explorando a API da OpenAI.pdf\":\\n\\n1. Inicialize o cliente da OpenAI utilizando o código fornecido no documento.\\n2. Crie um assistente com uma instrução específica, como por exemplo, um assistente que responda perguntas de matemática e tenha acesso à ferramenta de interpretação de código.\\n3. Crie uma thread de comunicação com o assistente, adicionando mensagens a ela.\\n4. Solicite ao assistente para rodar a thread e aguarde a finalização do processo.\\n5. Verifique a resposta gerada pelo assistente, solicitando a lista de mensagens da thread e extraindo a mensagem final em formato de texto.\\n\\nEsses passos envolvem a criação do assistente, a interação por meio de threads e a obtenção das respostas geradas pelo modelo de assistente da OpenAI em Python【8:0†source】【8:1†source】【8:3†source】.')\n",
      "[FileCitationAnnotation(end_index=864, file_citation=FileCitation(file_id='file-PovZdD8NM7TgpkKNvVe7sr'), start_index=852, text='【8:0†source】', type='file_citation'), FileCitationAnnotation(end_index=876, file_citation=FileCitation(file_id='file-PovZdD8NM7TgpkKNvVe7sr'), start_index=864, text='【8:1†source】', type='file_citation'), FileCitationAnnotation(end_index=888, file_citation=FileCitation(file_id='file-PovZdD8NM7TgpkKNvVe7sr'), start_index=876, text='【8:3†source】', type='file_citation')]\n",
      "FileCitation(file_id='file-PovZdD8NM7TgpkKNvVe7sr')\n",
      "FileCitation(file_id='file-PovZdD8NM7TgpkKNvVe7sr')\n",
      "FileCitation(file_id='file-PovZdD8NM7TgpkKNvVe7sr')\n"
     ]
    }
   ],
   "source": [
    "mensagens = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    ")\n",
    "\n",
    "mensagens = list(mensagens)[0].content[0].text\n",
    "print(mensagens)\n",
    "\n",
    "anotacoes = mensagens.annotations\n",
    "print(anotacoes)\n",
    "\n",
    "citacoes = []\n",
    "for index, anotacao in enumerate(anotacoes):\n",
    "    mensagens.value = mensagens.value.replace(anotacao.text, f'[{index}]')\n",
    "    if file_cit := getattr(anotacao, 'file_citation', None):\n",
    "        file = client.files.retrieve(file_cit.file_id)\n",
    "        citacoes.append(f'[{index}] {file.filename}')\n",
    "        print(file_cit)\n",
    "citacoes = '\\n'.join(citacoes)\n",
    "mensagens.value = f'{mensagens.value}\\n{citacoes}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para utilizar assistentes com Python, é possível seguir os seguintes passos conforme o documento \"Explorando a API da OpenAI.pdf\":\n",
      "\n",
      "1. Inicialize o cliente da OpenAI utilizando o código fornecido no documento.\n",
      "2. Crie um assistente com uma instrução específica, como por exemplo, um assistente que responda perguntas de matemática e tenha acesso à ferramenta de interpretação de código.\n",
      "3. Crie uma thread de comunicação com o assistente, adicionando mensagens a ela.\n",
      "4. Solicite ao assistente para rodar a thread e aguarde a finalização do processo.\n",
      "5. Verifique a resposta gerada pelo assistente, solicitando a lista de mensagens da thread e extraindo a mensagem final em formato de texto.\n",
      "\n",
      "Esses passos envolvem a criação do assistente, a interação por meio de threads e a obtenção das respostas geradas pelo modelo de assistente da OpenAI em Python[0][1][2].\n",
      "[0] Explorando a API da OpenAI.pdf\n",
      "[1] Explorando a API da OpenAI.pdf\n",
      "[2] Explorando a API da OpenAI.pdf\n"
     ]
    }
   ],
   "source": [
    "print(mensagens.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0] Explorando a API da OpenAI.pdf\\n[1] Explorando a API da OpenAI.pdf\\n[2] Explorando a API da OpenAI.pdf'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citacoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Para utilizar assistentes com Python, é possível seguir os seguintes passos conforme o documento \"Explorando a API da OpenAI.pdf\":\\n\\n1. Inicialize o cliente da OpenAI utilizando o código fornecido no documento.\\n2. Crie um assistente com uma instrução específica, como por exemplo, um assistente que responda perguntas de matemática e tenha acesso à ferramenta de interpretação de código.\\n3. Crie uma thread de comunicação com o assistente, adicionando mensagens a ela.\\n4. Solicite ao assistente para rodar a thread e aguarde a finalização do processo.\\n5. Verifique a resposta gerada pelo assistente, solicitando a lista de mensagens da thread e extraindo a mensagem final em formato de texto.\\n\\nEsses passos envolvem a criação do assistente, a interação por meio de threads e a obtenção das respostas geradas pelo modelo de assistente da OpenAI em Python[0][1][2].\\n[0] Explorando a API da OpenAI.pdf\\n[1] Explorando a API da OpenAI.pdf\\n[2] Explorando a API da OpenAI.pdf'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mensagens.value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
